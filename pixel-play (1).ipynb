{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":90860,"databundleVersionId":10740331,"sourceType":"competition"}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport cv2\nimport os\nimport PIL\nimport tensorflow as tf\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.utils import image_dataset_from_directory","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-14T15:34:26.850604Z","iopub.execute_input":"2025-01-14T15:34:26.850953Z","iopub.status.idle":"2025-01-14T15:34:34.380426Z","shell.execute_reply.started":"2025-01-14T15:34:26.850922Z","shell.execute_reply":"2025-01-14T15:34:34.379800Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"dataset_train_url = r\"/kaggle/input/vlg-recruitment-24-challenge/vlg-dataset/vlg-dataset/train\"\ndataset_test_url = r\"/kaggle/input/vlg-recruitment-24-challenge/vlg-dataset/vlg-dataset/test\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T15:34:34.381464Z","iopub.execute_input":"2025-01-14T15:34:34.381931Z","iopub.status.idle":"2025-01-14T15:34:34.385510Z","shell.execute_reply.started":"2025-01-14T15:34:34.381907Z","shell.execute_reply":"2025-01-14T15:34:34.384612Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import pathlib\ndata_train_dir=pathlib.Path(dataset_train_url)\ndata_test_dir=pathlib.Path(dataset_test_url)\ndata_train_dir,data_test_dir","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T15:34:34.386974Z","iopub.execute_input":"2025-01-14T15:34:34.387232Z","iopub.status.idle":"2025-01-14T15:34:34.398983Z","shell.execute_reply.started":"2025-01-14T15:34:34.387213Z","shell.execute_reply":"2025-01-14T15:34:34.398292Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"(PosixPath('/kaggle/input/vlg-recruitment-24-challenge/vlg-dataset/vlg-dataset/train'),\n PosixPath('/kaggle/input/vlg-recruitment-24-challenge/vlg-dataset/vlg-dataset/test'))"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"from tensorflow.keras.applications.efficientnet import preprocess_input\n\ndatagen = ImageDataGenerator(\n    rotation_range=30,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode=\"nearest\",\n    preprocessing_function=preprocess_input  # Preprocessing function for EfficientNetB0\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T15:34:34.400120Z","iopub.execute_input":"2025-01-14T15:34:34.400300Z","iopub.status.idle":"2025-01-14T15:34:34.413769Z","shell.execute_reply.started":"2025-01-14T15:34:34.400284Z","shell.execute_reply":"2025-01-14T15:34:34.412953Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"train_get=datagen.flow_from_directory(\n    data_train_dir,\n    target_size=(224,224),\n    batch_size=32,\n    class_mode='sparse',\n    shuffle=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T15:34:34.414586Z","iopub.execute_input":"2025-01-14T15:34:34.414885Z","iopub.status.idle":"2025-01-14T15:34:44.967260Z","shell.execute_reply.started":"2025-01-14T15:34:34.414864Z","shell.execute_reply":"2025-01-14T15:34:44.966565Z"}},"outputs":[{"name":"stdout","text":"Found 9544 images belonging to 40 classes.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"IMG_SIZE = 224\nBATCH_SIZE = 32\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T15:34:44.968152Z","iopub.execute_input":"2025-01-14T15:34:44.968455Z","iopub.status.idle":"2025-01-14T15:34:44.972096Z","shell.execute_reply.started":"2025-01-14T15:34:44.968424Z","shell.execute_reply":"2025-01-14T15:34:44.971202Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"from tensorflow.keras.applications import EfficientNetB0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T15:34:44.972825Z","iopub.execute_input":"2025-01-14T15:34:44.973071Z","iopub.status.idle":"2025-01-14T15:34:44.984266Z","shell.execute_reply.started":"2025-01-14T15:34:44.973043Z","shell.execute_reply":"2025-01-14T15:34:44.983667Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def build_model(num_classes):\n    inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n    model = EfficientNetB0(include_top=False, input_tensor=inputs, weights=\"imagenet\")\n\n    # Freeze the pretrained weights\n    model.trainable = False\n\n    # Rebuild top\n    x = layers.GlobalAveragePooling2D(name=\"avg_pool\")(model.output)\n\n    # Add a Dense layer with 128 units and ReLU activation\n    x = layers.Dense(128, activation='relu', name='dense_1')(x)\n\n    # Output layer\n    outputs = layers.Dense(num_classes, activation=\"softmax\", name=\"pred\")(x)\n\n    # Compile the model\n    model = keras.Model(inputs, outputs, name=\"EfficientNet\")\n    optimizer = keras.optimizers.Adam()\n    model.compile(\n        optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n    )\n    \n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T15:34:44.985091Z","iopub.execute_input":"2025-01-14T15:34:44.985373Z","iopub.status.idle":"2025-01-14T15:34:44.996355Z","shell.execute_reply.started":"2025-01-14T15:34:44.985345Z","shell.execute_reply":"2025-01-14T15:34:44.995727Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"model=build_model(40)\nfor layer in model.layers[-10:]:\n    layer.trainable = True\nmodel.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3), loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T15:34:44.998911Z","iopub.execute_input":"2025-01-14T15:34:44.999110Z","iopub.status.idle":"2025-01-14T15:34:47.245263Z","shell.execute_reply.started":"2025-01-14T15:34:44.999093Z","shell.execute_reply":"2025-01-14T15:34:47.244610Z"}},"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"model.fit(train_get, epochs=1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T15:34:47.246486Z","iopub.execute_input":"2025-01-14T15:34:47.246749Z","iopub.status.idle":"2025-01-14T15:39:02.098419Z","shell.execute_reply.started":"2025-01-14T15:34:47.246729Z","shell.execute_reply":"2025-01-14T15:39:02.097714Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 750ms/step - accuracy: 0.6276 - loss: 1.4028\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7cccb09de800>"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-6), loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T15:39:02.099346Z","iopub.execute_input":"2025-01-14T15:39:02.099877Z","iopub.status.idle":"2025-01-14T15:39:02.107545Z","shell.execute_reply.started":"2025-01-14T15:39:02.099854Z","shell.execute_reply":"2025-01-14T15:39:02.106948Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"model.fit(train_get, epochs=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T15:39:02.108380Z","iopub.execute_input":"2025-01-14T15:39:02.108674Z","iopub.status.idle":"2025-01-14T15:42:07.189687Z","shell.execute_reply.started":"2025-01-14T15:39:02.108628Z","shell.execute_reply":"2025-01-14T15:42:07.188788Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 544ms/step - accuracy: 0.8436 - loss: 0.4846\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7ccc8a3236d0>"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"for layer in model.layers[-25:]:\n    layer.trainable = True\nmodel.compile(optimizer=keras.optimizers.Adam(), loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T15:42:07.190630Z","iopub.execute_input":"2025-01-14T15:42:07.190974Z","iopub.status.idle":"2025-01-14T15:42:07.199587Z","shell.execute_reply.started":"2025-01-14T15:42:07.190937Z","shell.execute_reply":"2025-01-14T15:42:07.198705Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"model.fit(train_get, epochs=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T15:42:07.200505Z","iopub.execute_input":"2025-01-14T15:42:07.201122Z","iopub.status.idle":"2025-01-14T15:48:11.539201Z","shell.execute_reply.started":"2025-01-14T15:42:07.201087Z","shell.execute_reply":"2025-01-14T15:48:11.538480Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/2\n\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 552ms/step - accuracy: 0.7941 - loss: 0.6514\nEpoch 2/2\n\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 566ms/step - accuracy: 0.8546 - loss: 0.4347\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7cccb09dee00>"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"import os\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nfrom tensorflow.keras.applications.resnet50 import preprocess_input as preprocess_resnet\nfrom tensorflow.keras.applications.efficientnet import preprocess_input as preprocess_efficientnet\n\n# Function to load images from directory\ndef load_images_from_directory(directory, target_size=(224, 224)):\n    image_list = []\n    filenames = os.listdir(directory)\n    \n    for filename in filenames:\n        img_path = os.path.join(directory, filename)\n        \n        # Check if it's an image file (jpg, jpeg, png)\n        if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n            img = load_img(img_path, target_size=target_size)  # Load image with the target size\n            img_array = img_to_array(img)  # Convert image to array\n            image_list.append(img_array)\n    \n    # Convert list to a numpy array\n    return np.array(image_list), filenames\n\n# Load all images from the directory (replace 'data_test_dir' with your actual path)\nimages, filenames = load_images_from_directory(data_test_dir)\n\n# Preprocess for ResNet50\nimages_resnet = preprocess_resnet(images)  # Apply ResNet50-specific preprocessing\n\n# Preprocess for EfficientNetB0\nimages_efficientnet = preprocess_efficientnet(images)  # Apply EfficientNetB0-specific preprocessing\n\n# Now, images_resnet and images_efficientnet are preprocessed images ready for ResNet50 and EfficientNetB0\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T16:10:57.067154Z","iopub.execute_input":"2025-01-14T16:10:57.067449Z","iopub.status.idle":"2025-01-14T16:11:22.799923Z","shell.execute_reply.started":"2025-01-14T16:10:57.067426Z","shell.execute_reply":"2025-01-14T16:11:22.798987Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"Number of images loaded: {images.shape[0]}\")\nprint(filenames [:10])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T15:49:06.607938Z","iopub.execute_input":"2025-01-14T15:49:06.608163Z","iopub.status.idle":"2025-01-14T15:49:06.613014Z","shell.execute_reply.started":"2025-01-14T15:49:06.608143Z","shell.execute_reply":"2025-01-14T15:49:06.612165Z"}},"outputs":[{"name":"stdout","text":"Number of images loaded: 3000\n['02371.jpg', '00767.jpg', '02360.jpg', '00266.jpg', '02450.jpg', '01496.jpg', '01600.jpg', '00847.jpg', '00822.jpg', '00614.jpg']\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nimport pandas as pd\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.applications.resnet50 import decode_predictions\n\n\nclass_labels = {v: k for k, v in train_get.class_indices.items()}  # Reverse the class_indices dictionary\n\n\n# Define the 40 classes from train_get + 10 specific unseen classes\ndesired_classes = ['horse', 'collie', 'moose', 'fox', 'sheep', 'chimpanzee', 'gorilla', 'squirrel', 'rhinoceros', 'rabbit']\nall_classes = list(train_get.class_indices.keys()) + desired_classes  \n\n# Load ResNet50 with ImageNet weights (include the top classification layer)\nresnet_model = ResNet50(include_top=True, weights=\"imagenet\")\n\n# Make predictions using the trained model (for those seen 40 classes)\nmodel_predictions = model.predict(images_efficientnet)\n\n# Get the predicted class \npredicted_classes_model = tf.argmax(model_predictions, axis=-1).numpy()\n\n# Make predictions using ResNet50 for comparison\nresnet_predictions = resnet_model.predict(images_resnet)\n\n# Decode predictions from ResNet50 to human-readable class labels\ndecoded_predictions = decode_predictions(resnet_predictions, top=10)  # Get top 10 predictions for each image\n\n# Prepare a list to store the results\ntest_predictions = []\n\n# Iterate over the images and compare predictions\nfor i in range(len(filenames)):\n    img_name = filenames[i]  # Corresponding image filename\n\n    # Get the class label predicted by trained model\n    predicted_class_index_model = predicted_classes_model[i]\n    predicted_class_label_model = class_labels[predicted_class_index_model]\n    predicted_class_probability_model = model_predictions[i][predicted_class_index_model]  # Get probability of your model's prediction\n\n    # Get the decoded predictions from ResNet50\n    resnet_class_labels = [prediction[1] for prediction in decoded_predictions[i]]  # Extract all class labels\n    resnet_class_probabilities = [prediction[2] for prediction in decoded_predictions[i]]  # Extract all probabilities\n\n    # Initialize final prediction variable\n    final_prediction = predicted_class_label_model  # Default to trained model's prediction\n\n    # Flag to indicate whether a valid prediction from ResNet50 was found\n    resnet_predicted_valid_class = False\n\n    # Compare ResNet50's predictions with trained model's predictions\n    for j in range(len(resnet_class_labels)):\n        if resnet_class_labels[j] in all_classes:\n            # If ResNet50 predicted a class that is either in the training set or the desired unseen classes\n            resnet_predicted_valid_class = True  # We found a valid class from ResNet50\n\n            # If ResNet50's predicted class probability is higher, take ResNet50's prediction\n            if resnet_class_probabilities[j] > predicted_class_probability_model:\n                final_prediction = resnet_class_labels[j]\n            break  # Exit loop after selecting the prediction\n\n    # If ResNet50 didn't predict a valid class, fallback to model's prediction\n    if not resnet_predicted_valid_class:\n        final_prediction = predicted_class_label_model  # Ensure the model's prediction is used if ResNet50 is not valid\n\n    # Append the result (filename, final predicted class label)\n    test_predictions.append((img_name, final_prediction))\n\n# Save predictions to a CSV file\nsubmission = pd.DataFrame(test_predictions, columns=['image_id', 'predicted_class_label'])\nsubmission.to_csv(\"predictions.csv\", index=False)\n\n# Print a sample of the saved predictions\nprint(submission.head(5))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T16:11:33.595660Z","iopub.execute_input":"2025-01-14T16:11:33.596067Z","iopub.status.idle":"2025-01-14T16:12:00.867751Z","shell.execute_reply.started":"2025-01-14T16:11:33.596031Z","shell.execute_reply":"2025-01-14T16:12:00.866856Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step\n\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 110ms/step\n    image_id predicted_class_label\n0  02371.jpg           siamese+cat\n1  00767.jpg                beaver\n2  02360.jpg             chihuahua\n3  00266.jpg                  wolf\n4  02450.jpg                   pig\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"# Save predictions to a CSV file in the correct directory for Kaggle\nsubmission.to_csv(\"/kaggle/working/predictions.csv\", index=False)\n\n# Print the saved CSV file location\nprint(\"CSV file saved to: /kaggle/working/predictions.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T16:12:10.587322Z","iopub.execute_input":"2025-01-14T16:12:10.587735Z","iopub.status.idle":"2025-01-14T16:12:10.596300Z","shell.execute_reply.started":"2025-01-14T16:12:10.587702Z","shell.execute_reply":"2025-01-14T16:12:10.595452Z"}},"outputs":[{"name":"stdout","text":"CSV file saved to: /kaggle/working/predictions.csv\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}